{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#quick look\n",
    "\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The dataset is made of 8x8 images of digits\n",
    "#we could load them using matplotlib.pyplot.imread.\n",
    "\n",
    "_, axes = plt.subplots(2, 6)\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for ax, (image, label) in zip(axes[0, :], images_and_labels[:6]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('%i' % label)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))#-1 means take all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neuron network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ususally deal with complex situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78  0  0  0  0  0  0  2  0  0]\n",
      " [ 0 83  4  0  0  0  0  0  3  3]\n",
      " [ 0  2 78  4  0  0  0  0  1  0]\n",
      " [ 0  1  2 71  0  1  0  0  5  5]\n",
      " [ 0  1  0  0 88  0  0  2  0  0]\n",
      " [ 0  0  0  0  0 89  2  1  1 10]\n",
      " [ 0  4  1  0  0  1 80  0  3  0]\n",
      " [ 2  0  0  0  2  0  0 84  1  1]\n",
      " [ 0  7  1  2  0  2  1  2 74  2]\n",
      " [ 2  2  0  2  1  7  0  2  0 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        80\n",
      "           1       0.83      0.89      0.86        93\n",
      "           2       0.91      0.92      0.91        85\n",
      "           3       0.90      0.84      0.87        85\n",
      "           4       0.97      0.97      0.97        91\n",
      "           5       0.89      0.86      0.88       103\n",
      "           6       0.96      0.90      0.93        89\n",
      "           7       0.90      0.93      0.92        90\n",
      "           8       0.84      0.81      0.83        91\n",
      "           9       0.78      0.83      0.80        92\n",
      "\n",
      "    accuracy                           0.89       899\n",
      "   macro avg       0.89      0.89      0.89       899\n",
      "weighted avg       0.89      0.89      0.89       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=12, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 93,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0, 83,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0, 80,  0,  2,  0,  1,  2,  0],\n",
       "       [ 0,  1,  0,  0, 89,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1, 99,  1,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0, 89,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 90,  0,  0],\n",
       "       [ 0, 11,  0,  3,  0,  0,  0,  1, 76,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  2,  0, 89]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        80\n",
      "           1       0.89      1.00      0.94        93\n",
      "           2       1.00      0.98      0.99        85\n",
      "           3       0.96      0.94      0.95        85\n",
      "           4       0.98      0.98      0.98        91\n",
      "           5       0.98      0.96      0.97       103\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.95      1.00      0.97        90\n",
      "           8       0.96      0.84      0.89        91\n",
      "           9       0.98      0.97      0.97        92\n",
      "\n",
      "    accuracy                           0.97       899\n",
      "   macro avg       0.97      0.97      0.97       899\n",
      "weighted avg       0.97      0.97      0.97       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
